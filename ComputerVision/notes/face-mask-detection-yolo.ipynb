{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d54d7d0",
   "metadata": {},
   "source": [
    "# Face Mask Detection with YOLO (Real-time)\n",
    "\n",
    "This notebook builds a face mask detection system optimized for real-time speed and accuracy using the Ultralytics YOLO family. It covers setup, data preparation (YOLO format), training, evaluation, inference, webcam demo, performance tuning, and model export.\n",
    "\n",
    "Folder location: `notebooks/face-mask-detection-yolo.ipynb`\n",
    "\n",
    "Classes: `no_mask`, `mask`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900fd83d",
   "metadata": {},
   "source": [
    "## 1) Set Up Environment and GPU\n",
    "\n",
    "Detect CUDA, select device (cpu/cuda), set deterministic flags, and print versions for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60791799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and GPU setup\n",
    "import os, sys, platform, random\n",
    "from pathlib import Path\n",
    "\n",
    "# Torch may be installed later; keep this cell tolerant if torch isn't present yet\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "except Exception:\n",
    "    TORCH_AVAILABLE = False\n",
    "\n",
    "# Device selection\n",
    "CUDA_AVAILABLE = TORCH_AVAILABLE and torch.cuda.is_available()\n",
    "DEVICE = 'cuda' if CUDA_AVAILABLE else 'cpu'\n",
    "\n",
    "# Determinism and seeds\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "if TORCH_AVAILABLE:\n",
    "    torch.manual_seed(SEED)\n",
    "    if CUDA_AVAILABLE:\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Print versions for reproducibility\n",
    "print({\n",
    "    'python': sys.version.split()[0],\n",
    "    'platform': platform.platform(),\n",
    "    'device': DEVICE,\n",
    "    'torch': torch.__version__ if TORCH_AVAILABLE else 'not-installed',\n",
    "})\n",
    "\n",
    "# Optional: show GPUs\n",
    "if CUDA_AVAILABLE:\n",
    "    print('CUDA GPU count:', torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f'- [{i}]', torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b0040",
   "metadata": {},
   "source": [
    "## 2) Install Dependencies\n",
    "\n",
    "Installs required libraries. GPU is recommended but not required. If you want ONNX GPU runtime, include onnxruntime-gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b7ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages if missing\n",
    "import importlib, sys, subprocess\n",
    "\n",
    "def pip_install(pkg):\n",
    "    try:\n",
    "        importlib.import_module(pkg.split('==')[0].split('[')[0])\n",
    "        return\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(f'Installing {pkg} ...')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
    "\n",
    "# Core deps\n",
    "for pkg in ['ultralytics', 'opencv-python', 'onnxruntime-gpu; platform_system==\"Windows\"']:\n",
    "    try:\n",
    "        if ';' in pkg:  # handle environment markers simply\n",
    "            base, marker = pkg.split(';', 1)\n",
    "            # basic check: only install on Windows for the example marker\n",
    "            if 'Windows' in marker and platform.system() == 'Windows':\n",
    "                pip_install(base)\n",
    "        else:\n",
    "            pip_install(pkg)\n",
    "    except Exception as e:\n",
    "        print('Note: optional package failed or skipped:', pkg, e)\n",
    "\n",
    "# Verify imports and versions\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "print('cv2:', cv2.__version__)\n",
    "print('ultralytics:', YOLO.__module__.split('.')[0])\n",
    "\n",
    "# Torch and CUDA checks\n",
    "try:\n",
    "    import torch\n",
    "    print('torch:', torch.__version__, '| cuda available:', torch.cuda.is_available())\n",
    "except Exception as e:\n",
    "    print('torch not installed or failed to import:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c495ee",
   "metadata": {},
   "source": [
    "## 3) Define Project Paths\n",
    "\n",
    "Define ROOT, data_dir, runs_dir, and weights paths relative to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59dfeeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: E:\\VSCODE\\Data-Science-Monorepo\\ComputerVision\\notes\n",
      "DATA_DIR: E:\\VSCODE\\Data-Science-Monorepo\\ComputerVision\\ComputerVision\\FaceMaskDetection_YOLO\\data\n",
      "RUNS_DIR: E:\\VSCODE\\Data-Science-Monorepo\\ComputerVision\\ComputerVision\\FaceMaskDetection_YOLO\\runs\n",
      "WEIGHTS_DIR: E:\\VSCODE\\Data-Science-Monorepo\\ComputerVision\\ComputerVision\\FaceMaskDetection_YOLO\\runs\\weights\n"
     ]
    }
   ],
   "source": [
    "# Paths relative to this notebook\n",
    "from pathlib import Path\n",
    "ROOT = Path.cwd().resolve()\n",
    "DATA_DIR = ROOT.parent / 'ComputerVision' / 'FaceMaskDetection_YOLO' / 'data'\n",
    "RUNS_DIR = ROOT.parent / 'ComputerVision' / 'FaceMaskDetection_YOLO' / 'runs'\n",
    "WEIGHTS_DIR = RUNS_DIR / 'weights'\n",
    "\n",
    "for p in [DATA_DIR, RUNS_DIR, WEIGHTS_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('ROOT:', ROOT)\n",
    "print('DATA_DIR:', DATA_DIR)\n",
    "print('RUNS_DIR:', RUNS_DIR)\n",
    "print('WEIGHTS_DIR:', WEIGHTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c041a",
   "metadata": {},
   "source": [
    "## 4) Download or Prepare Dataset (YOLO format)\n",
    "\n",
    "Expected structure under `data/face-mask/`:\n",
    "- train/images, train/labels\n",
    "- val/images, val/labels\n",
    "- test/images, test/labels\n",
    "\n",
    "Each label file uses YOLO txt format per image: `class cx cy w h` normalized to [0,1].\n",
    "\n",
    "Pick one option below: unzip a local archive or ensure the folders already exist.\n",
    "\n",
    "#link: https://www.kaggle.com/datasets/aditya276/face-mask-dataset-yolo-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create expected directories if missing and optionally unzip a local archive\n",
    "#link: https://www.kaggle.com/datasets/aditya276/face-mask-dataset-yolo-format\n",
    "from pathlib import Path\n",
    "import shutil, zipfile\n",
    "\n",
    "FM_ROOT = DATA_DIR / 'dataset'\n",
    "for split in ['train', 'val', 'test']:\n",
    "    (FM_ROOT / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    (FM_ROOT / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Dataset root:', FM_ROOT)\n",
    "\n",
    "# Option A: Unzip an existing archive placed in DATA_DIR (e.g., face-mask-yolo.zip)\n",
    "ARCHIVE = DATA_DIR / 'face_mask.zip'\n",
    "if ARCHIVE.exists():\n",
    "    print('Found archive, unzipping:', ARCHIVE)\n",
    "    with zipfile.ZipFile(ARCHIVE, 'r') as zf:\n",
    "        zf.extractall(DATA_DIR)\n",
    "    print('Unzip done. Ensure extracted structure matches expected YOLO layout.')\n",
    "else:\n",
    "    print('No archive found at', ARCHIVE)\n",
    "\n",
    "# Minimal validation: number of images vs labels in each split\n",
    "for split in ['train', 'val', 'test']:\n",
    "    imgs = sorted((FM_ROOT / split / 'images').glob('*.*'))\n",
    "    labels = sorted((FM_ROOT / split / 'labels').glob('*.txt'))\n",
    "    print(split, 'images:', len(imgs), '| labels:', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83af2c",
   "metadata": {},
   "source": [
    "## 5) Create data.yaml\n",
    "\n",
    "Create a YOLO data config with paths and class names ['mask', 'no_mask', 'mask_incorrect']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18bb960a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FM_ROOT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n\u001b[32m      3\u001b[39m data_yaml = {\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[43mFM_ROOT\u001b[49m),\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mtrain/images\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mval/images\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mtest/images\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnc\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mno_mask\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmask\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m }\n\u001b[32m     12\u001b[39m DATA_YAML_PATH = DATA_DIR / \u001b[33m'\u001b[39m\u001b[33mdata.yaml\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(DATA_YAML_PATH, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'FM_ROOT' is not defined"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "data_yaml = {\n",
    "    'path': str(FM_ROOT),\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'test': 'test/images',\n",
    "    'nc': 2,\n",
    "    'names': ['no_mask', 'mask']\n",
    "}\n",
    "\n",
    "DATA_YAML_PATH = DATA_DIR / 'data.yaml'\n",
    "with open(DATA_YAML_PATH, 'w') as f:\n",
    "    yaml.safe_dump(data_yaml, f, sort_keys=False)\n",
    "\n",
    "print('Wrote', DATA_YAML_PATH)\n",
    "print(Path(DATA_YAML_PATH).read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469dbeaf",
   "metadata": {},
   "source": [
    "## 6) Visualize Training Samples\n",
    "\n",
    "Randomly preview labeled images to verify dataset quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names = data_yaml['names']  # ['no_mask', 'mask']\n",
    "colors = [tuple(np.random.randint(0,255,3).tolist()) for _ in names]\n",
    "\n",
    "img_paths = sorted((FM_ROOT / 'train' / 'images').glob('*.*'))\n",
    "random.shuffle(img_paths)\n",
    "\n",
    "def draw_yolo_boxes(img_path):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        return None\n",
    "    h, w = img.shape[:2]\n",
    "    label_path = (img_path.parent.parent / 'labels' / (img_path.stem + '.txt'))\n",
    "    if label_path.exists():\n",
    "        for line in Path(label_path).read_text().strip().splitlines():\n",
    "            cls, cx, cy, bw, bh = map(float, line.split())\n",
    "            cls = int(cls)\n",
    "            x1 = int((cx - bw/2) * w)\n",
    "            y1 = int((cy - bh/2) * h)\n",
    "            x2 = int((cx + bw/2) * w)\n",
    "            y2 = int((cy + bh/2) * h)\n",
    "            color = colors[cls % len(colors)]\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), color, 2)\n",
    "            if 0 <= cls < len(names):\n",
    "                cv2.putText(img, names[cls], (x1, max(0,y1-6)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            else:\n",
    "                cv2.putText(img, str(cls), (x1, max(0,y1-6)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "cols = 3\n",
    "rows = 2\n",
    "plt.figure(figsize=(12,8))\n",
    "for i, p in enumerate(img_paths[:cols*rows]):\n",
    "    img = draw_yolo_boxes(p)\n",
    "    if img is None:\n",
    "        continue\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf3588e",
   "metadata": {},
   "source": [
    "## 7) Train YOLO Model\n",
    "\n",
    "We use a small YOLO model (yolov8n) for real-time performance. Adjust epochs and batch size as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fd140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU diagnostics: Torch/Torchvision/CUDA & NMS availability\n",
    "try:\n",
    "    import torch, torchvision\n",
    "    print({\n",
    "        'torch': torch.__version__,\n",
    "        'torch_cuda_available': torch.cuda.is_available(),\n",
    "        'torch_cuda_version': getattr(torch.version, 'cuda', 'none'),\n",
    "        'torchvision': getattr(torchvision, '__version__', 'unknown'),\n",
    "    })\n",
    "    if torch.cuda.is_available():\n",
    "        print('GPU count:', torch.cuda.device_count())\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f'- [{i}]', torch.cuda.get_device_name(i))\n",
    "    try:\n",
    "        from torchvision.ops import nms\n",
    "        dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        boxes = torch.tensor([[0,0,10,10],[1,1,9,9]], dtype=torch.float32, device=dev)\n",
    "        scores = torch.tensor([0.9,0.8], dtype=torch.float32, device=dev)\n",
    "        try:\n",
    "            idx = nms(boxes, scores, 0.5)\n",
    "            loc = 'CUDA' if dev == 'cuda' else 'CPU'\n",
    "            print(f'torchvision.ops.nms OK on {loc}. kept indices:', idx.tolist())\n",
    "        except NotImplementedError as e:\n",
    "            print('NotImplementedError from torchvision::nms -> missing CUDA ops; training will fall back to CPU with AMP disabled unless you install a CUDA-enabled torchvision matching torch/CUDA.')\n",
    "    except Exception as e:\n",
    "        print('torchvision.ops.nms import/run failed:', e)\n",
    "    # Show what the notebook thinks the device is\n",
    "    try:\n",
    "        print('Notebook DEVICE variable:', DEVICE)\n",
    "    except NameError:\n",
    "        pass\n",
    "except Exception as e:\n",
    "    print('Diagnostics failed:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07df4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize model (nano for speed; switch to 'yolov8s.pt' for better accuracy)\n",
    "base_weights = 'yolov8n.pt'\n",
    "model = YOLO(base_weights)\n",
    "\n",
    "EPOCHS = int(os.getenv('EPOCHS', 55))\n",
    "BATCH = int(os.getenv('BATCH', 10))\n",
    "IMGSZ = int(os.getenv('IMGSZ', 640))\n",
    "WORKERS = int(os.getenv('WORKERS', 6))\n",
    "\n",
    "# Print torch/torchvision versions to help debug CUDA NMS issues\n",
    "try:\n",
    "    import torch, torchvision\n",
    "    print('torch:', torch.__version__, '| cuda available:', torch.cuda.is_available())\n",
    "    print('torchvision:', getattr(torchvision, '__version__', 'unknown'))\n",
    "except Exception as _e:\n",
    "    print('Version probe failed:', _e)\n",
    "\n",
    "# Train with graceful fallback if CUDA NMS is unavailable in torchvision\n",
    "try:\n",
    "    results = model.train(\n",
    "        data=str(DATA_YAML_PATH),\n",
    "        imgsz=IMGSZ,\n",
    "        epochs=EPOCHS,\n",
    "        batch=BATCH,\n",
    "        device=0 if DEVICE=='cuda' else 'cpu',\n",
    "        workers=WORKERS,\n",
    "        project=str(RUNS_DIR),\n",
    "        name='train/mask-yolo',\n",
    "        patience=20,\n",
    "        # leave amp=True by default; Ultralytics will run an AMP check\n",
    "    )\n",
    "except NotImplementedError as e:\n",
    "    msg = str(e)\n",
    "    if 'torchvision::nms' in msg and DEVICE == 'cuda':\n",
    "        print('\\n[WARN] CUDA NMS from torchvision is not available for your build.\\n'\n",
    "              'Falling back to CPU training with AMP disabled.\\n'\n",
    "              'To restore GPU training, install a torchvision build that matches your torch/CUDA.\\n')\n",
    "        results = model.train(\n",
    "            data=str(DATA_YAML_PATH),\n",
    "            imgsz=IMGSZ,\n",
    "            epochs=EPOCHS,\n",
    "            batch=BATCH,\n",
    "            device='cpu',\n",
    "            workers=max(0, min(WORKERS, 2)),  # be conservative on Windows\n",
    "            project=str(RUNS_DIR),\n",
    "            name='train/mask-yolo',\n",
    "            patience=20,\n",
    "            amp=False,\n",
    "            val=False,  # skip val to avoid NMS during training; you can run val later explicitly\n",
    "        )\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "print('Training complete. Best weights should be in runs/train/mask-yolo/weights/best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f383c6e0",
   "metadata": {},
   "source": [
    "## 8) Evaluate Model Performance\n",
    "\n",
    "Compute mAP, precision/recall, and plot confusion matrix and PR curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed1e0126",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RUNS_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load best weights and evaluate\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m best_weights = \u001b[43mRUNS_DIR\u001b[49m / \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mmask-yolo\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mweights\u001b[39m\u001b[33m'\u001b[39m / \u001b[33m'\u001b[39m\u001b[33mbest.pt\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m best_weights.exists(), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest weights not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_weights\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m model = YOLO(\u001b[38;5;28mstr\u001b[39m(best_weights))\n",
      "\u001b[31mNameError\u001b[39m: name 'RUNS_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "# Load best weights and evaluate\n",
    "best_weights = RUNS_DIR / 'train' / 'mask-yolo' / 'weights' / 'best.pt'\n",
    "assert best_weights.exists(), f\"Best weights not found: {best_weights}\"\n",
    "model = YOLO(str(best_weights))\n",
    "\n",
    "val_results = model.val(data=str(DATA_YAML_PATH), imgsz=IMGSZ, device=0 if DEVICE=='cuda' else 'cpu', project=str(RUNS_DIR), name='val')\n",
    "print(val_results.results_dict)\n",
    "\n",
    "# The Ultralytics API saves confusion_matrix.png and PR curves under runs/val\n",
    "print('Val artifacts saved to:', RUNS_DIR / 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a21e45",
   "metadata": {},
   "source": [
    "## 9) Run Inference on Sample Images\n",
    "\n",
    "Run predictions on the test split and save annotated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "model = YOLO(str(best_weights))\n",
    "\n",
    "# Ensure class name mapping is correct for display\n",
    "yaml_names = data_yaml['names']\n",
    "try:\n",
    "    # model.names can be dict or list; normalize and override when lengths match\n",
    "    if hasattr(model, 'names'):\n",
    "        if isinstance(model.names, dict):\n",
    "            current = [model.names[i] for i in sorted(model.names.keys())]\n",
    "        else:\n",
    "            current = list(model.names)\n",
    "        if len(current) == len(yaml_names):\n",
    "            model.names = {i: n for i, n in enumerate(yaml_names)}\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "TEST_IMAGES_DIR = FM_ROOT / 'test' / 'images'\n",
    "PRED_OUT = RUNS_DIR / 'predict'\n",
    "PRED_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "res = model.predict(source=str(TEST_IMAGES_DIR), imgsz=IMGSZ, conf=0.25, iou=0.5, save=True, save_txt=False, project=str(RUNS_DIR), name='predict')\n",
    "print('Predictions saved to:', RUNS_DIR / 'predict')\n",
    "\n",
    "# Print a short summary for the first few images\n",
    "names_map = model.names if isinstance(model.names, dict) else {i:n for i,n in enumerate(yaml_names)}\n",
    "for r in res[:5]:\n",
    "    boxes = r.boxes\n",
    "    if boxes is None:\n",
    "        continue\n",
    "    print(Path(r.path).name, 'detections:')\n",
    "    for b in boxes:\n",
    "        cls = int(b.cls.item())\n",
    "        conf = float(b.conf.item())\n",
    "        xyxy = b.xyxy[0].tolist()\n",
    "        label = names_map.get(cls, str(cls))\n",
    "        print('  -', label, f'{conf:.2f}', [round(v,1) for v in xyxy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1f3912",
   "metadata": {},
   "source": [
    "## 10) Real-Time Webcam Inference\n",
    "\n",
    "Press 'q' to quit the stream. If you have multiple cameras, try index 1 or 2. On Windows PowerShell, ensure camera permissions are allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "602dbbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using weights: E:\\VSCODE\\Data-Science-Monorepo\\ComputerVision\\FaceMaskDetection_YOLO\\runs\\train\\mask-yolo\\weights\\best.pt\n",
      "Class names from data.yaml: ['no_mask', 'mask']\n",
      "Starting webcam. Press q to quit...\n",
      "Starting webcam. Press q to quit...\n"
     ]
    }
   ],
   "source": [
    "# Self-contained real-time webcam inference (run this cell alone)\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1) Resolve project paths relative to this notebook\n",
    "ROOT = Path.cwd().resolve()  # .../ComputerVision/notes\n",
    "BASE_DIR = ROOT.parent / 'FaceMaskDetection_YOLO'\n",
    "DATA_YAML_PATH = BASE_DIR / 'data' / 'data.yaml'\n",
    "RUNS_DIR = BASE_DIR / 'runs'\n",
    "\n",
    "# 2) Find best weights automatically (or use BEST_WEIGHTS env var)\n",
    "def find_best_weights() -> Path | None:\n",
    "    cand_env = os.getenv('BEST_WEIGHTS')\n",
    "    if cand_env:\n",
    "        p = Path(cand_env)\n",
    "        if p.exists():\n",
    "            return p\n",
    "        print(f\"[WARN] BEST_WEIGHTS set but not found: {p}\")\n",
    "    # common default location from training section\n",
    "    default = RUNS_DIR / 'train' / 'mask-yolo' / 'weights' / 'best.pt'\n",
    "    if default.exists():\n",
    "        return default\n",
    "    # fallback: pick most recent best.pt anywhere under runs\n",
    "    if RUNS_DIR.exists():\n",
    "        bests = list(RUNS_DIR.rglob('best.pt'))\n",
    "        if bests:\n",
    "            bests.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "            return bests[0]\n",
    "    return None\n",
    "\n",
    "best_path = find_best_weights()\n",
    "assert best_path is not None and best_path.exists(), (\"No best.pt found. Set BEST_WEIGHTS env var to a valid path or run training.\\n\"\n",
    "                                                     f\"Searched under: {RUNS_DIR}\")\n",
    "print('Using weights:', best_path)\n",
    "\n",
    "# 3) Load model\n",
    "model = YOLO(str(best_path))\n",
    "\n",
    "# 4) Determine class names for overlay\n",
    "names: list[str] | None = None\n",
    "# Try to read from data.yaml first (keeps your chosen order; e.g., ['no_mask', 'mask'])\n",
    "try:\n",
    "    import yaml  # lazy import\n",
    "    if DATA_YAML_PATH.exists():\n",
    "        with open(DATA_YAML_PATH, 'r', encoding='utf-8') as f:\n",
    "            cfg = yaml.safe_load(f) or {}\n",
    "        yaml_names = cfg.get('names')\n",
    "        if isinstance(yaml_names, (list, tuple)) and len(yaml_names) > 0:\n",
    "            names = list(yaml_names)\n",
    "            print('Class names from data.yaml:', names)\n",
    "except Exception as _:\n",
    "    pass\n",
    "\n",
    "# Fallback to model.names if needed\n",
    "try:\n",
    "    model_names = model.names if hasattr(model, 'names') else None\n",
    "    if names is None or (isinstance(model_names, (dict, list)) and len(model_names) == len(names) == 0):\n",
    "        if isinstance(model_names, dict) and model_names:\n",
    "            names = [model_names[i] for i in sorted(model_names.keys())]\n",
    "        elif isinstance(model_names, list) and model_names:\n",
    "            names = list(model_names)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Final guard: default names if still missing\n",
    "if not names:\n",
    "    names = ['class_0', 'class_1']\n",
    "    print('[WARN] Falling back to default class names:', names)\n",
    "\n",
    "# Optional: enforce display mapping to data.yaml order when lengths match\n",
    "try:\n",
    "    if hasattr(model, 'names') and len(names) == (len(model.names) if not isinstance(model.names, dict) else len(model.names.keys())):\n",
    "        model.names = {i: n for i, n in enumerate(names)}\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# 5) Device/precision\n",
    "CUDA = torch.cuda.is_available()\n",
    "DEVICE_ARG = 0 if CUDA else 'cpu'\n",
    "HALF = True if CUDA else False  # Ultralytics handles casting; we toggle via flag only\n",
    "\n",
    "# 6) Colors for classes\n",
    "rng = np.random.default_rng(123)\n",
    "colors = [tuple(int(c) for c in rng.integers(0, 255, 3)) for _ in names]\n",
    "\n",
    "# 7) Open webcam (set CAM_INDEX env var to change camera)\n",
    "cam_index = int(os.getenv('CAM_INDEX', '0'))\n",
    "cap = cv2.VideoCapture(cam_index)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f'Webcam index {cam_index} not accessible. Try a different CAM_INDEX (e.g., 1 or 2).')\n",
    "\n",
    "prev = time.time()\n",
    "print('Starting webcam. Press q to quit...')\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        print('Failed to grab frame')\n",
    "        break\n",
    "\n",
    "    img = frame.copy()\n",
    "\n",
    "    # Inference (retry in float32 if half precision dtype mismatch occurs)\n",
    "    try:\n",
    "        results = model.predict(source=img, imgsz=640, conf=0.35, iou=0.5, device=DEVICE_ARG, half=HALF, verbose=False)\n",
    "    except RuntimeError as e:\n",
    "        if 'dtype' in str(e).lower():\n",
    "            print('[WARN] dtype mismatch with half precision; retrying with half=False')\n",
    "            HALF = False\n",
    "            results = model.predict(source=img, imgsz=640, conf=0.35, iou=0.5, device=DEVICE_ARG, half=False, verbose=False)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    r = results[0]\n",
    "    if r.boxes is not None:\n",
    "        for b in r.boxes:\n",
    "            cls = int(b.cls.item())\n",
    "            conf = float(b.conf.item())\n",
    "            x1, y1, x2, y2 = map(int, b.xyxy[0].tolist())\n",
    "            color = colors[cls % len(colors)]\n",
    "            label = names[cls] if 0 <= cls < len(names) else str(cls)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(img, f\"{label} {conf:.2f}\", (x1, max(0, y1 - 6)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    now = time.time()\n",
    "    fps = 1.0 / max(1e-6, (now - prev))\n",
    "    prev = now\n",
    "    cv2.putText(img, f'FPS: {fps:.1f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Face Mask Detection - YOLO', img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b1f18e",
   "metadata": {},
   "source": [
    "## 11) Performance Tuning for Real-Time\n",
    "\n",
    "Quickly benchmark FPS with different image sizes and half precision settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, numpy as np, cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "model = YOLO(str(best_weights))\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    model.to('cuda')\n",
    "\n",
    "\n",
    "def benchmark(imgsz_list=(320, 480, 640), half_list=(False, True), warmup=5, iters=30):\n",
    "    results = []\n",
    "    dummy = np.random.randint(0,255,(720,1280,3), dtype=np.uint8)\n",
    "    for imgsz in imgsz_list:\n",
    "        for half in half_list:\n",
    "            if half and not CUDA:\n",
    "                continue\n",
    "            # warmup\n",
    "            for _ in range(warmup):\n",
    "                model.predict(source=dummy, imgsz=imgsz, device=0 if CUDA else 'cpu', half=half, verbose=False)\n",
    "            t0 = time.time()\n",
    "            for _ in range(iters):\n",
    "                model.predict(source=dummy, imgsz=imgsz, device=0 if CUDA else 'cpu', half=half, verbose=False)\n",
    "            dt = time.time() - t0\n",
    "            fps = iters / dt\n",
    "            results.append({'imgsz': imgsz, 'half': half, 'fps': round(fps,1)})\n",
    "    return results\n",
    "\n",
    "bench = benchmark()\n",
    "for r in bench:\n",
    "    print(r)\n",
    "\n",
    "print('Tip: yolov8n is faster, yolov8s is more accurate; choose based on your target FPS and accuracy.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4530a1fe",
   "metadata": {},
   "source": [
    "## 12) Export Model (ONNX) and Verify\n",
    "\n",
    "Export the trained model to ONNX and verify with ONNX Runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65790f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2, os\n",
    "\n",
    "model = YOLO(str(best_weights))\n",
    "export_path = model.export(format='onnx', dynamic=True, opset=12)\n",
    "print('Exported ONNX path:', export_path)\n",
    "\n",
    "# Verify with ONNX Runtime\n",
    "try:\n",
    "    import onnxruntime as ort\n",
    "    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if ort.get_device() == 'GPU' else ['CPUExecutionProvider']\n",
    "    sess = ort.InferenceSession(export_path, providers=providers)\n",
    "\n",
    "    # Prepare one dummy frame\n",
    "    dummy = np.random.randint(0,255,(640,640,3), dtype=np.uint8)\n",
    "    img = cv2.cvtColor(dummy, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (640,640))\n",
    "    img = img.transpose(2,0,1)[None].astype(np.float32) / 255.0\n",
    "\n",
    "    inputs = {sess.get_inputs()[0].name: img}\n",
    "    outputs = sess.run(None, inputs)\n",
    "    print('ONNX forward ok. Output shapes:', [np.array(o).shape for o in outputs])\n",
    "except Exception as e:\n",
    "    print('ONNX Runtime verification skipped or failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234fe30d",
   "metadata": {},
   "source": [
    "## 13) Save and Load Trained Weights\n",
    "\n",
    "Document the weights path and reload to test a quick prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e565339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "print('Best weights:', best_weights)\n",
    "model = YOLO(str(best_weights))\n",
    "\n",
    "# Run a quick single-image test if any test image exists\n",
    "sample_imgs = sorted((FM_ROOT / 'test' / 'images').glob('*.*'))\n",
    "if sample_imgs:\n",
    "    res = model.predict(source=str(sample_imgs[0]), imgsz=IMGSZ, conf=0.25, save=True, project=str(RUNS_DIR), name='quickcheck')\n",
    "    print('Quick check saved to:', RUNS_DIR / 'quickcheck')\n",
    "else:\n",
    "    print('No test images found for quick check.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33792ea",
   "metadata": {},
   "source": [
    "## 14) Minimal Unit Tests (Postprocessing and I/O)\n",
    "\n",
    "Lightweight checks to catch obvious issues without heavy dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple checks\n",
    "assert len(data_yaml['names']) == 2\n",
    "assert data_yaml['names'][0] == 'no_mask' and data_yaml['names'][1] == 'mask'\n",
    "assert set(Path(str(FM_ROOT)).glob('**/images')).__class__  # existence of paths check\n",
    "\n",
    "# Color mapping reproducibility\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(123)\n",
    "colors = [tuple(rng.integers(0,255,3).tolist()) for _ in data_yaml['names']]\n",
    "assert len(colors) == 2\n",
    "\n",
    "# Webcam availability check (non-fatal)\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print('Webcam not accessible â€” skipping live capture test.')\n",
    "else:\n",
    "    ok, frame = cap.read()\n",
    "    print('Webcam frame shape:' if ok else 'Failed to read a frame')\n",
    "    if ok:\n",
    "        print(frame.shape)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e111f105",
   "metadata": {},
   "source": [
    "## 15) Notebook File Path\n",
    "\n",
    "This notebook is saved at: `notebooks/face-mask-detection-yolo.ipynb`\n",
    "\n",
    "Training artifacts and exports are saved under: `Computer Vision/FaceMaskDetection_YOLO/runs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c02182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset summary and quick visualization grid for YOLO labels\n",
    "# Safe to run multiple times; it reads paths from data.yaml\n",
    "from pathlib import Path\n",
    "import random\n",
    "import math\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# 1) Load dataset config\n",
    "DATA_YAML = Path(r\"E:\\VSCODE\\Data-Science-Monorepo\\ComputerVision\\FaceMaskDetection_YOLO\\data\\data.yaml\")\n",
    "with open(DATA_YAML, 'r', encoding='utf-8') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "root = Path(cfg.get('path') or DATA_YAML.parent)\n",
    "# cfg['train'] / cfg['val'] / cfg['test'] are like 'train/images'\n",
    "\n",
    "def split_dirs(key: str):\n",
    "    rel = Path(cfg.get(key, f\"{key}/images\"))\n",
    "    img_dir = root / rel\n",
    "    lbl_dir = img_dir.parent / 'labels'\n",
    "    return img_dir, lbl_dir\n",
    "\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "# 2) Print counts per split\n",
    "summary = []\n",
    "for s in splits:\n",
    "    img_dir, lbl_dir = split_dirs(s)\n",
    "    imgs = list(img_dir.glob('*.*')) if img_dir.exists() else []\n",
    "    # Only count common image extensions\n",
    "    imgs = [p for p in imgs if p.suffix.lower() in {'.jpg', '.jpeg', '.png', '.bmp'}]\n",
    "    lbls = list(lbl_dir.glob('*.txt')) if lbl_dir.exists() else []\n",
    "    summary.append((s, len(imgs), len(lbls), img_dir, lbl_dir))\n",
    "\n",
    "print(\"Dataset root:\", root)\n",
    "for s, ni, nl, img_dir, lbl_dir in summary:\n",
    "    print(f\"{s:>5}: images={ni:5d} | labels={nl:5d} | {img_dir.relative_to(root)}  /  {lbl_dir.relative_to(root)}\")\n",
    "\n",
    "# 3) Visualize a grid of labeled images for a chosen split\n",
    "#    If you want another split, set SPLIT='val' or 'test'.\n",
    "SPLIT = 'train'\n",
    "N = 12  # number of images to show\n",
    "cols = 4\n",
    "rows = math.ceil(N / cols)\n",
    "\n",
    "img_dir, lbl_dir = split_dirs(SPLIT)\n",
    "assert img_dir.exists(), f\"Image dir not found: {img_dir}\"\n",
    "assert lbl_dir.exists(), f\"Label dir not found: {lbl_dir}\"\n",
    "\n",
    "names = cfg.get('names') or []\n",
    "\n",
    "# Helper to read yolo txt labels\n",
    "# Each line: class x_center y_center width height (normalized to [0,1])\n",
    "def read_yolo_labels(label_path, img_w, img_h):\n",
    "    boxes = []\n",
    "    if not label_path.exists():\n",
    "        return boxes\n",
    "    with open(label_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:  # some datasets might have more (xywh + conf), keep first 5\n",
    "                parts = parts[:5]\n",
    "            try:\n",
    "                cls, xc, yc, w, h = parts\n",
    "                cls = int(float(cls))\n",
    "                xc, yc, w, h = map(float, (xc, yc, w, h))\n",
    "            except Exception:\n",
    "                continue\n",
    "            # convert to pixel xyxy\n",
    "            bw = w * img_w\n",
    "            bh = h * img_h\n",
    "            cx = xc * img_w\n",
    "            cy = yc * img_h\n",
    "            x1 = max(0, cx - bw / 2)\n",
    "            y1 = max(0, cy - bh / 2)\n",
    "            boxes.append((cls, x1, y1, bw, bh))  # store as (cls, x1,y1,w,h)\n",
    "    return boxes\n",
    "\n",
    "# Get candidate images\n",
    "images = [p for p in img_dir.glob('*.*') if p.suffix.lower() in {'.jpg', '.jpeg', '.png', '.bmp'}]\n",
    "if not images:\n",
    "    print(f\"No images found in {img_dir}\")\n",
    "else:\n",
    "    random.shuffle(images)\n",
    "    sel = images[:N]\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 3.5*rows))\n",
    "    if not isinstance(axes, (list, tuple)):\n",
    "        axes = axes.reshape(rows, cols)\n",
    "\n",
    "    for ax, img_path in zip(axes.flat, sel):\n",
    "        # Load image via matplotlib (no OpenCV dependency)\n",
    "        img = plt.imread(str(img_path))\n",
    "        if img.dtype.kind == 'f':  # some readers return float [0,1]\n",
    "            img_h, img_w = img.shape[:2]\n",
    "        else:\n",
    "            img_h, img_w = img.shape[:2]\n",
    "\n",
    "        label_path = lbl_dir / (img_path.stem + '.txt')\n",
    "        boxes = read_yolo_labels(label_path, img_w, img_h)\n",
    "\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(img_path.name, fontsize=8)\n",
    "        ax.axis('off')\n",
    "\n",
    "        for cls, x1, y1, bw, bh in boxes:\n",
    "            rect = patches.Rectangle((x1, y1), bw, bh, linewidth=1.5, edgecolor='lime', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            if 0 <= cls < len(names):\n",
    "                ax.text(x1, y1 - 2, names[cls], color='yellow', fontsize=7,\n",
    "                        bbox=dict(facecolor='black', alpha=0.4, pad=1))\n",
    "\n",
    "    # Hide any unused axes\n",
    "    for i in range(len(sel), rows*cols):\n",
    "        axes.flat[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
